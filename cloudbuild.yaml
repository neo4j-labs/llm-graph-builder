substitutions:
  _REGION: us-central1
  _REPO: cloud-run-repo

options:
  logging: CLOUD_LOGGING_ONLY

steps:

# 1. Detect Environment by Branch
- name: gcr.io/cloud-builders/gcloud
  id: detect-env
  entrypoint: bash
  args:
    - -c
    - |
      if [[ "$BRANCH_NAME" == "main" ]]; then
        echo "prod" > /workspace/env
      elif [[ "$BRANCH_NAME" == "staging" ]]; then
        echo "staging" > /workspace/env
      elif [[ "$BRANCH_NAME" == "dev-ci-cd" ]]; then
        echo "dev_ci_cd" > /workspace/env
      else
        echo "Branch $BRANCH_NAME does not correspond to a deployment environment."
        exit 1
      fi

# 2. Backend â€“ Python
- name: gcr.io/cloud-builders/docker
  id: build-backend
  entrypoint: bash
  args:
    - -c
    - |
      ENV=$(cat /workspace/env)
      docker build \
        -t ${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO}/backend-$${ENV}:$SHORT_SHA \
        ./backend

- name: gcr.io/cloud-builders/docker
  id: push-backend
  entrypoint: bash
  args:
    - -c
    - |
      ENV=$(cat /workspace/env)
      docker push ${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO}/backend-$${ENV}:$SHORT_SHA

- name: gcr.io/google.com/cloudsdktool/cloud-sdk
  id: deploy-backend
  entrypoint: bash
  args:
    - -c
    - |
      ENV=$(cat /workspace/env)
      
      python3 - <<'PY' > /workspace/env_vars.json
      import os, json
      keys = [
        "OPENAI_API_KEY","DIFFBOT_API_KEY","BUCKET_UPLOAD_FILE","BUCKET_FAILED_FILE",
        "PROJECT_ID","GCS_FILE_CACHE","TRACK_TOKEN_USAGE","TOKEN_TRACKER_DB_URI",
        "TOKEN_TRACKER_DB_USERNAME","TOKEN_TRACKER_DB_PASSWORD","TOKEN_TRACKER_DB_DATABASE",
        "DEFAULT_DIFFBOT_CHAT_MODEL","RAGAS_EMBEDDING_MODEL","YOUTUBE_TRANSCRIPT_PROXY",
        "BEDROCK_EMBEDDING_MODEL","LLM_MODEL_CONFIG_OPENAI_GPT_5_1","LLM_MODEL_CONFIG_OPENAI_GPT_5_MINI",
        "LLM_MODEL_CONFIG_GEMINI_2_5_FLASH","LLM_MODEL_CONFIG_GEMINI_2_5_PRO","LLM_MODEL_CONFIG_DIFFBOT",
        "LLM_MODEL_CONFIG_GROQ_LLAMA3_1_8B","LLM_MODEL_CONFIG_ANTHROPIC_CLAUDE_4_5_SONNET",
        "LLM_MODEL_CONFIG_ANTHROPIC_CLAUDE_4_5_HAIKU","LLM_MODEL_CONFIG_FIREWORKS_QWEN3_30B",
        "LLM_MODEL_CONFIG_FIREWORKS_GPT_OSS","LLM_MODEL_CONFIG_FIREWORKS_DEEPSEEK_V3",
        "LLM_MODEL_CONFIG_BEDROCK_NOVA_MICRO_V1","LLM_MODEL_CONFIG_BEDROCK_NOVA_LITE_V1",
        "LLM_MODEL_CONFIG_BEDROCK_NOVA_PRO_V1","LLM_MODEL_CONFIG_OLLAMA_LLAMA3","LOG_LEVEL"
      ]
      def val(k):
          return os.environ.get(k) or os.environ.get("_"+k) or ""
      d = {k: val(k) for k in keys}
      if not d.get("PROJECT_ID"):
          d["PROJECT_ID"] = os.environ.get("PROJECT_ID","")
      if not d.get("LOG_LEVEL"):
          d["LOG_LEVEL"] = "info"
      json.dump(d, open("/workspace/env_vars.json","w"), indent=2)
      PY
      
      echo "Deploying to Cloud Run service: backend-$${ENV}-new"
      cat /workspace/env_vars.json

      gcloud run deploy backend-$${ENV}-new \
        --image ${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO}/backend-$${ENV}:$SHORT_SHA \
        --region ${_REGION} \
        --platform managed \
        --allow-unauthenticated \
        --env-vars-file=/workspace/env_vars.json

- name: gcr.io/google.com/cloudsdktool/cloud-sdk
  id: deploy-backend-processing
  entrypoint: bash
  args:
    - -c
    - |
      ENV=$(cat /workspace/env)

      # Build JSON env file that preserves commas/quotes/newlines.
      python3 - <<'PY' > /workspace/env_vars.json
      import os, json
      keys = [
        "OPENAI_API_KEY","DIFFBOT_API_KEY","BUCKET_UPLOAD_FILE","BUCKET_FAILED_FILE",
        "PROJECT_ID","GCS_FILE_CACHE","TRACK_TOKEN_USAGE","TOKEN_TRACKER_DB_URI",
        "TOKEN_TRACKER_DB_USERNAME","TOKEN_TRACKER_DB_PASSWORD","TOKEN_TRACKER_DB_DATABASE",
        "DEFAULT_DIFFBOT_CHAT_MODEL","RAGAS_EMBEDDING_MODEL","YOUTUBE_TRANSCRIPT_PROXY",
        "BEDROCK_EMBEDDING_MODEL","LLM_MODEL_CONFIG_OPENAI_GPT_5_1","LLM_MODEL_CONFIG_OPENAI_GPT_5_MINI",
        "LLM_MODEL_CONFIG_GEMINI_2_5_FLASH","LLM_MODEL_CONFIG_GEMINI_2_5_PRO","LLM_MODEL_CONFIG_DIFFBOT",
        "LLM_MODEL_CONFIG_GROQ_LLAMA3_1_8B","LLM_MODEL_CONFIG_ANTHROPIC_CLAUDE_4_5_SONNET",
        "LLM_MODEL_CONFIG_ANTHROPIC_CLAUDE_4_5_HAIKU","LLM_MODEL_CONFIG_FIREWORKS_QWEN3_30B",
        "LLM_MODEL_CONFIG_FIREWORKS_GPT_OSS","LLM_MODEL_CONFIG_FIREWORKS_DEEPSEEK_V3",
        "LLM_MODEL_CONFIG_BEDROCK_NOVA_MICRO_V1","LLM_MODEL_CONFIG_BEDROCK_NOVA_LITE_V1",
        "LLM_MODEL_CONFIG_BEDROCK_NOVA_PRO_V1","LLM_MODEL_CONFIG_OLLAMA_LLAMA3","LOG_LEVEL"
      ]
      def val(k):
          return os.environ.get(k) or os.environ.get("_"+k) or ""
      d = {k: val(k) for k in keys}
      if not d.get("PROJECT_ID"):
          d["PROJECT_ID"] = os.environ.get("PROJECT_ID","")
      if not d.get("LOG_LEVEL"):
          d["LOG_LEVEL"] = "info"
      json.dump(d, open("/workspace/env_vars.json","w"), indent=2)

      # Deploy using env file (preserves special characters)
      gcloud run deploy backend-$${ENV}-processing-new \
        --image ${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO}/backend-$${ENV}:$SHORT_SHA \
        --region ${_REGION} \
        --platform managed \
        --allow-unauthenticated \
        --env-vars-file=/workspace/env_vars.json

# - name: gcr.io/cloud-builders/docker
#   id: build-frontend
#   entrypoint: bash
#   args:
#     - -c
#     - |
#       ENV=$(cat /workspace/env)
#       docker build \
#         --build-arg NEXT_PUBLIC_ENV=$ENV \
#         --build-arg NEXT_PUBLIC_API_URL=https://backend-$ENV-$PROJECT_ID.run.app \
#         -t $_REGION-docker.pkg.dev/$PROJECT_ID/$_REPO/frontend-$ENV:$SHORT_SHA \
#         ./frontend

# - name: gcr.io/cloud-builders/docker
#   id: push-frontend
#   entrypoint: bash
#   args:
#     - -c
#     - |
#       ENV=$(cat /workspace/env)
#       docker push $_REGION-docker.pkg.dev/$PROJECT_ID/$_REPO/frontend-$ENV:$SHORT_SHA

# - name: gcr.io/google.com/cloudsdktool/cloud-sdk
#   id: deploy-frontend
#   entrypoint: bash
#   args:
#     - -c
#     - |
#       ENV=$(cat /workspace/env)
#       gcloud run deploy frontend-$ENV \
#         --image $_REGION-docker.pkg.dev/$PROJECT_ID/$_REPO/frontend-$ENV:$SHORT_SHA \
#         --region $_REGION \
#         --platform managed \
#         --allow-unauthenticated \
#         --set-env-vars \
#           ENV=$ENV,\
#           NEXT_PUBLIC_API_URL=https://backend-$ENV-$PROJECT_ID.run.app