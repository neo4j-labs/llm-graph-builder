OPENAI_API_KEY = "" #Mandatory- Default_Value = "openai_api_key"  #This is required if you are using openai embedding model
EMBEDDING_MODEL = "" #OPTIONAL- Default_Value =""  #this can be openai or vertexai or by default all-MiniLM-L6-v2
RAGAS_EMBEDDING_MODEL = "" #OPTIONAL- Default_Value ="openai"  #Keep blank if you want to use all-MiniLM-L6-v2 for ragas embeddings
IS_EMBEDDING = "" #OPTIONAL- Default_Value ="True" --Flag to enable text embedding
BUCKET_UPLOAD_FILE = "" #OPTIONAL- Default_Value ="gcs bucket name" -- use the gcs bucket to upload local file to gcs cloud
BUCKET_FAILED_FILE = "" #OPTIONAL- Default_Value ="gcs bucket name" -- use the gcs bucket for failed file while extraction
PROJECT_ID = ""         #OPTIONAL- Default Value ="gcp project id"  -- gcp project id from where the gcs bucket is created
KNN_MIN_SCORE = "" #OPTIONAL- Default_Value ="0.8" --Minimum score for KNN algorithm 
GCP_LOG_METRICS_ENABLED = "" #OPTIONAL- Default_Value = "False" -- Enable to logs metrics on gcp cloud logging
UPDATE_GRAPH_CHUNKS_PROCESSED = "" #OPTIONAL- Default_Value ="20" -- Number of chunks processed to update the graph
NEO4J_URI = "" #OPTIONAL- Default_Value ="Neo4j URL"
NEO4J_USERNAME = "" #OPTIONAL- Default_Value = "Neo4J database username"
NEO4J_PASSWORD = "" #OPTIONAL- Default_Value = "Neo4j database user password"
NEO4J_DATABASE = "" #OPTIONAL- Default_Value = "Neo4j database user database"
GCS_FILE_CACHE = "" #OPTIONAL- Default_Value = "False" #save the file into GCS or local, SHould be True or False
ENABLE_USER_AGENT = "" #OPTIONAL- Default_Value = "False"
NEO4J_USER_AGENT="" #OPTIONAL- Default_Value = "LLM-Graph-Builder"
ENTITY_EMBEDDING="" #OPTIONAL- Default_Value = "False"-- Value based on whether to create embeddings for entities suitable for entity vector mode
DUPLICATE_SCORE_VALUE = "" #OPTIONAL- Default_Value = "0.97" -- Node score value to match duplicate node
DUPLICATE_TEXT_DISTANCE = "" #OPTIONAL- Default_Value = "3" --This value used to find distance for all node pairs in the graph and calculated based on node properties
DEFAULT_DIFFBOT_CHAT_MODEL="" #OPTIONAL- Default_Value = "openai_gpt_5_mini"  #whichever model specified here , need to add config for that model in below format)
GRAPH_CLEANUP_MODEL="" #OPTIONAL- Default_Value = "openai_gpt_5_mini" -- Model name to clean-up graph in post processing
BEDROCK_EMBEDDING_MODEL="" #OPTIONAL - Default_Value = "model_name,aws_access_key,aws_secret_key,region_name" -- If want to use bedrock embedding #model_name="amazon.titan-embed-text-v1"
YOUTUBE_TRANSCRIPT_PROXY="" #Mandatory --Proxy key required to process youtube video for getting transcript --Sample Value ="https://user:pass@domain:port"
EFFECTIVE_SEARCH_RATIO="" #OPTIONAL- Default_Value = "5"
MAX_TOKEN_CHUNK_SIZE="" #OPTIONAL- Default_Value = "10000" #Max token used to process/extract the file content.
#examples
LLM_MODEL_CONFIG_openai_gpt_5.2="gpt-5.2,openai-key"
LLM_MODEL_CONFIG_openai_gpt_5_mini="gpt-5-mini,openai-key"
LLM_MODEL_CONFIG_openai_gpt_4.1="gpt-4.1,openai-key"
LLM_MODEL_CONFIG_openai_gpt_4.1_mini="gpt-4.1-mini,openai-key"
LLM_MODEL_CONFIG_gemini_2.5_flash="gemini-2.5-flash"
LLM_MODEL_CONFIG_gemini_2.5_pro="gemini-2.5-pro"
LLM_MODEL_CONFIG_diffbot="diffbot,diffbot_api_key"
LLM_MODEL_CONFIG_groq_llama3.1_8b="llama-3.1-8b-instant,base_url,groq_api_key"
LLM_MODEL_CONFIG_anthropic_claude_4.5_sonnet="claude-sonnet-4-5-20250929,anthropic_api_key"
LLM_MODEL_CONFIG_anthropic_claude_4.5_haiku="claude-haiku-4-5-20250929,anthropic_api_key"
LLM_MODEL_CONFIG_llama4_maverick="Llama-4-Maverick-17B-128E-Instruct-FP8,https://api.llama.com/compat/v1/,LLM|1207839134334841|NT9iYvy201sMmsOJB6spkslwoiM"
LLM_MODEL_CONFIG_azure_ai_gpt_4o="gpt-4o,https://YOUR-ENDPOINT.openai.azure.com/,azure_api_key,api_version"
LLM_MODEL_CONFIG_fireworks_qwen3_30b="accounts/fireworks/models/qwen3-30b-a3b,fireworks_api_key"
LLM_MODEL_CONFIG_fireworks_gpt_oss="accounts/fireworks/models/gpt-oss-120b,fireworks_api_key"
LLM_MODEL_CONFIG_fireworks_deepseek_v3="accounts/fireworks/models/deepseek-v3p1,fireworks_api_key"
LLM_MODEL_CONFIG_bedrock_nova_micro_v1="amazon.nova-micro-v1:0,aws_access_key,aws_secret_key,region_name"
LLM_MODEL_CONFIG_bedrock_nova_lite_v1="amazon.nova-lite-v1:0,aws_access_key,aws_secret_key,region_name"
LLM_MODEL_CONFIG_bedrock_nova_pro_v1="amazon.nova-pro-v1:0,aws_access_key,aws_secret_key,region_name"
LLM_MODEL_CONFIG_ollama_llama3="llama3_model_name,model_local_url"
TRACK_TOKEN_USAGE="true" #Add this if you want to track token usage
DAILY_TOKENS_LIMIT="250000" #Mandatory if TRACK_TOKEN_USAGE is true
MONTHLY_TOKENS_LIMIT="1000000" #Mandatory if TRACK_TOKEN_USAGE is true
TOKEN_TRACKER_DB_URI=""  #Mandatory if TRACK_TOKEN_USAGE is true
TOKEN_TRACKER_DB_USERNAME="" #Mandatory if TRACK_TOKEN_USAGE is true
TOKEN_TRACKER_DB_PASSWORD="" #Mandatory if TRACK_TOKEN_USAGE is true
TOKEN_TRACKER_DB_DATABASE="" #Mandatory if TRACK_TOKEN_USAGE is true