OPENAI_API_KEY = ""   #This is required if you are using openai embedding model
EMBEDDING_MODEL = "all-MiniLM-L6-v2"  #this can be openai or vertexai or by default all-MiniLM-L6-v2
RAGAS_EMBEDDING_MODEL = "openai"  #Keep blank if you want to use all-MiniLM-L6-v2 for ragas embeddings
IS_EMBEDDING = "TRUE"   
KNN_MIN_SCORE = "0.94"
# Enable Gemini (default is False) | Can be False or True
GEMINI_ENABLED = False
# Enable Google Cloud logs (default is False) | Can be False or True
GCP_LOG_METRICS_ENABLED = False
NUMBER_OF_CHUNKS_TO_COMBINE = 6
UPDATE_GRAPH_CHUNKS_PROCESSED = 20
NEO4J_URI = ""
NEO4J_USERNAME = ""
NEO4J_PASSWORD = ""
NEO4J_DATABASE = ""
AWS_ACCESS_KEY_ID =  ""
AWS_SECRET_ACCESS_KEY = ""
LANGCHAIN_API_KEY = ""
LANGCHAIN_PROJECT = ""
LANGCHAIN_TRACING_V2 = ""
LANGCHAIN_ENDPOINT = ""
GCS_FILE_CACHE = "" #save the file into GCS or local, Should be True or False
NEO4J_USER_AGENT=""
ENABLE_USER_AGENT = ""
LLM_MODEL_CONFIG_model_version=""
ENTITY_EMBEDDING="TRUE"   # TRUE or FALSE based on whether to create embeddings for entities suitable for entity vector mode
DUPLICATE_SCORE_VALUE =0.97
DUPLICATE_TEXT_DISTANCE =3
DEFAULT_DIFFBOT_CHAT_MODEL="openai_gpt_4o"  #whichever model specified here , need to add config for that model in below format)
#examples
LLM_MODEL_CONFIG_openai_gpt_5.1="gpt-5.1,openai-key"
LLM_MODEL_CONFIG_openai_gpt_5_mini="gpt-5-mini,openai-key"
LLM_MODEL_CONFIG_openai_gpt_4.1="gpt-4.1,openai-key"
LLM_MODEL_CONFIG_openai_gpt_4.1_mini="gpt-4.1-mini,openai-key"
LLM_MODEL_CONFIG_gemini_2.5_flash="gemini-2.5-flash"
LLM_MODEL_CONFIG_gemini_2.5_pro="gemini-2.5-pro"
LLM_MODEL_CONFIG_diffbot="diffbot,diffbot_api_key"
LLM_MODEL_CONFIG_groq_llama3.1_8b="llama-3.1-8b-instant,base_url,groq_api_key"
LLM_MODEL_CONFIG_anthropic_claude_4.5_sonnet="claude-sonnet-4-5-20250929,anthropic_api_key"
LLM_MODEL_CONFIG_llama4_maverick="Llama-4-Maverick-17B-128E-Instruct-FP8,https://api.llama.com/compat/v1/,LLM|1207839134334841|NT9iYvy201sMmsOJB6spkslwoiM"
LLM_MODEL_CONFIG_azure_ai_gpt_4o="gpt-4o,https://YOUR-ENDPOINT.openai.azure.com/,azure_api_key,api_version"
LLM_MODEL_CONFIG_fireworks_qwen3_30b="accounts/fireworks/models/qwen3-30b-a3b,fireworks_api_key"
LLM_MODEL_CONFIG_fireworks_gpt_oss="accounts/fireworks/models/gpt-oss-120b,fireworks_api_key"
LLM_MODEL_CONFIG_fireworks_deepseek_v3="accounts/fireworks/models/deepseek-v3p1,fireworks_api_key"
LLM_MODEL_CONFIG_bedrock_nova_micro_v1="amazon.nova-micro-v1:0,aws_access_key,aws_secret_key,region_name"
LLM_MODEL_CONFIG_bedrock_nova_lite_v1="amazon.nova-lite-v1:0,aws_access_key,aws_secret_key,region_name"
LLM_MODEL_CONFIG_bedrock_nova_pro_v1="amazon.nova-pro-v1:0,aws_access_key,aws_secret_key,region_name"
LLM_MODEL_CONFIG_fireworks_gpt_oss="accounts/fireworks/models/gpt-oss-120b,fireworks_api_key"
LLM_MODEL_CONFIG_ollama_llama3="llama3_model_name,model_local_url"
YOUTUBE_TRANSCRIPT_PROXY="https://user:pass@domain:port"
EFFECTIVE_SEARCH_RATIO=5
GRAPH_CLEANUP_MODEL="openai_gpt_4o"
BEDROCK_EMBEDDING_MODEL="model_name,aws_access_key,aws_secret_key,region_name"                       #model_name="amazon.titan-embed-text-v2.0"
MAX_TOKEN_CHUNK_SIZE=2000 #Max token used to process/extract the file content.