{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca84cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_core.documents import Document\n",
    "import google.auth\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import time\n",
    "import os\n",
    "# Set up project info and credentials\n",
    "PROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "credentials, _ = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff129685",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"Alice is a data scientist who works at Acme Corp.\",\n",
    "    \"John is a software engineer and Alice's colleague.\",\n",
    "    \"Acme Corp is based in San Francisco.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5020c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample text chunks\n",
    "chunk_docs = [Document(page_content=text) for text in sample_texts]\n",
    "\n",
    "# Define allowed nodes and relationships\n",
    "# allowed_nodes = None\n",
    "# allowed_relationships = None\n",
    "allowed_nodes = [\"Person\", \"Organization\", \"Location\"]\n",
    "allowed_relationships = [(\"Person\", \"works_at\", \"Organization\"), (\"Organization\", \"based_in\", \"Location\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af38dcc",
   "metadata": {},
   "source": [
    "### Comparing models for time taken to extract graph informationm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a58debd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Gemini 2.5 Flash ---\n",
      "Time taken to create graph: 3.31 seconds for model gemini-2.5-flash\n",
      "Nodes extracted :  [Node(id='Alice', type='Person', properties={}), Node(id='Acme Corp.', type='Organization', properties={})]\n",
      "Relationships extracted :  [Relationship(source=Node(id='Alice', type='Person', properties={}), target=Node(id='Acme Corp.', type='Organization', properties={}), type='WORKS_AT', properties={})]\n",
      "Nodes extracted :  []\n",
      "Relationships extracted :  []\n",
      "Nodes extracted :  [Node(id='Acme Corp', type='Organization', properties={}), Node(id='San Francisco', type='Location', properties={})]\n",
      "Relationships extracted :  [Relationship(source=Node(id='Acme Corp', type='Organization', properties={}), target=Node(id='San Francisco', type='Location', properties={}), type='BASED_IN', properties={})]\n",
      "\n",
      "--- Running Gemini 3 Preview ---\n",
      "Time taken to create graph: 9.46 seconds for model gemini-3-flash-preview\n",
      "Nodes extracted :  [Node(id='Alice', type='Person', properties={}), Node(id='Acme Corp', type='Organization', properties={})]\n",
      "Relationships extracted :  [Relationship(source=Node(id='Alice', type='Person', properties={}), target=Node(id='Acme Corp', type='Organization', properties={}), type='WORKS_AT', properties={})]\n",
      "Nodes extracted :  [Node(id='John', type='Person', properties={}), Node(id='Alice', type='Person', properties={})]\n",
      "Relationships extracted :  []\n",
      "Nodes extracted :  [Node(id='Acme Corp', type='Organization', properties={}), Node(id='San Francisco', type='Location', properties={})]\n",
      "Relationships extracted :  [Relationship(source=Node(id='Acme Corp', type='Organization', properties={}), target=Node(id='San Francisco', type='Location', properties={}), type='BASED_IN', properties={})]\n",
      "\n",
      "Summary:\n",
      "Gemini 2.5 Flash: 3.31 seconds\n",
      "Gemini 3 Preview: 9.46 seconds\n"
     ]
    }
   ],
   "source": [
    "def run_graph_transformer(model_name, credentials, project, location, chunk_docs, allowed_nodes, allowed_relationships,ignore_tool_usage):\n",
    "    nest_asyncio.apply()\n",
    "    llm = ChatVertexAI(\n",
    "        model_name=model_name,\n",
    "        credentials=credentials,\n",
    "        project=project,\n",
    "        location=location,\n",
    "        temperature=0,\n",
    "    )\n",
    "    graph_transformer = LLMGraphTransformer(\n",
    "        llm=llm,\n",
    "        node_properties=False,\n",
    "        relationship_properties=False,\n",
    "        allowed_nodes=allowed_nodes,\n",
    "        allowed_relationships=allowed_relationships,\n",
    "        ignore_tool_usage=ignore_tool_usage,\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    graph_document_list = asyncio.get_event_loop().run_until_complete(\n",
    "        graph_transformer.aconvert_to_graph_documents(chunk_docs)\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(f\"Time taken to create graph: {elapsed:.2f} seconds for model {model_name}\")\n",
    "    for doc in graph_document_list:\n",
    "        print(\"Nodes extracted : \", doc.nodes)\n",
    "        print(\"Relationships extracted : \", doc.relationships)\n",
    "    return elapsed\n",
    "\n",
    "# Model names\n",
    "MODEL1 = \"gemini-2.5-flash\"\n",
    "LOCATION1=\"us-central1\"\n",
    "\n",
    "MODEL2 = \"gemini-3-flash-preview\"\n",
    "LOCATION2=\"global\"\n",
    "ignore_tool_usage=False\n",
    "\n",
    "# Run and compare\n",
    "print(\"\\n--- Running Gemini 2.5 Flash ---\")\n",
    "time1 = run_graph_transformer(MODEL1, credentials, PROJECT_ID, LOCATION1, chunk_docs, allowed_nodes, allowed_relationships,ignore_tool_usage)\n",
    "\n",
    "print(\"\\n--- Running Gemini 3 Preview ---\")\n",
    "time2 = run_graph_transformer(MODEL2, credentials, PROJECT_ID, LOCATION2, chunk_docs, allowed_nodes, allowed_relationships,ignore_tool_usage)\n",
    "\n",
    "print(f\"\\nSummary:\\nGemini 2.5 Flash: {time1:.2f} seconds\\nGemini 3 Preview: {time2:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0945dc",
   "metadata": {},
   "source": [
    "##### Error when ignore tools usage is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639a603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Gemini 3 Preview ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m ignore_tool_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Running Gemini 3 Preview ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m time2 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_graph_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCATION2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_relationships\u001b[49m\u001b[43m,\u001b[49m\u001b[43mignore_tool_usage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSummary:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGemini 3 Preview: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m, in \u001b[0;36mrun_graph_transformer\u001b[0;34m(model_name, credentials, project, location, chunk_docs, allowed_nodes, allowed_relationships, ignore_tool_usage)\u001b[0m\n\u001b[1;32m     10\u001b[0m graph_transformer \u001b[38;5;241m=\u001b[39m LLMGraphTransformer(\n\u001b[1;32m     11\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     12\u001b[0m     node_properties\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     ignore_tool_usage\u001b[38;5;241m=\u001b[39mignore_tool_usage,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 19\u001b[0m graph_document_list \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maconvert_to_graph_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     23\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/asyncio/futures.py:202\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/asyncio/tasks.py:316\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    314\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/site-packages/langchain_experimental/graph_transformers/llm.py:1031\u001b[0m, in \u001b[0;36mLLMGraphTransformer.aconvert_to_graph_documents\u001b[0;34m(self, documents, config)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03mAsynchronously convert a sequence of documents into graph documents.\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1028\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maprocess_response(document, config))\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents\n\u001b[1;32m   1030\u001b[0m ]\n\u001b[0;32m-> 1031\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/asyncio/tasks.py:385\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/site-packages/langchain_experimental/graph_transformers/llm.py:951\u001b[0m, in \u001b[0;36mLLMGraphTransformer.aprocess_response\u001b[0;34m(self, document, config)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_schema, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    950\u001b[0m     raw_schema \u001b[38;5;241m=\u001b[39m raw_schema\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m--> 951\u001b[0m parsed_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_repair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parsed_json, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    953\u001b[0m     parsed_json \u001b[38;5;241m=\u001b[39m [parsed_json]\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/site-packages/json_repair/json_repair.py:120\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(json_str, skip_json_loads, logging, stream_stable)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloads\u001b[39m(\n\u001b[1;32m    103\u001b[0m     json_str: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    104\u001b[0m     skip_json_loads: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    105\u001b[0m     logging: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m     stream_stable: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[JSONReturnType, Tuple[JSONReturnType, List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]], \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    This function works like `json.loads()` except that it will fix your JSON in the process.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    It is a wrapper around the `repair_json()` function with `return_objects=True`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m        Union[JSONReturnType, Tuple[JSONReturnType, List[Dict[str, str]]], str]: The repaired JSON object or a tuple with the repaired JSON object and repair log.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepair_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_json_loads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_json_loads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_stable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_stable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/site-packages/json_repair/json_repair.py:92\u001b[0m, in \u001b[0;36mrepair_json\u001b[0;34m(json_str, return_objects, skip_json_loads, logging, json_fd, ensure_ascii, chunk_length, stream_stable)\u001b[0m\n\u001b[1;32m     90\u001b[0m         parsed_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_fd)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m         parsed_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m     94\u001b[0m     parsed_json \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse()\n",
      "File \u001b[0;32m/opt/conda/envs/py312/lib/python3.12/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not list"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    \"Alice is a data scientist who works at Acme Corp.\",\n",
    "    \"John is a software engineer and Alice's colleague.\",\n",
    "    \"Acme Corp is based in San Francisco.\"\n",
    "]\n",
    "\n",
    "def run_graph_transformer(model_name, credentials, project, location, chunk_docs, allowed_nodes, allowed_relationships,ignore_tool_usage):\n",
    "    nest_asyncio.apply()\n",
    "    llm = ChatVertexAI(\n",
    "        model_name=model_name,\n",
    "        credentials=credentials,\n",
    "        project=project,\n",
    "        location=location,\n",
    "        temperature=0,\n",
    "    )\n",
    "    graph_transformer = LLMGraphTransformer(\n",
    "        llm=llm,\n",
    "        node_properties=False,\n",
    "        relationship_properties=False,\n",
    "        allowed_nodes=allowed_nodes,\n",
    "        allowed_relationships=allowed_relationships,\n",
    "        ignore_tool_usage=ignore_tool_usage,\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    graph_document_list = asyncio.get_event_loop().run_until_complete(\n",
    "        graph_transformer.aconvert_to_graph_documents(chunk_docs)\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(f\"Time taken to create graph: {elapsed:.2f} seconds for model {model_name}\")\n",
    "    for doc in graph_document_list:\n",
    "        print(\"Nodes extracted : \", doc.nodes)\n",
    "        print(\"Relationships extracted : \", doc.relationships)\n",
    "    return elapsed\n",
    "\n",
    "# Model names\n",
    "MODEL2 = \"gemini-3-flash-preview\"\n",
    "LOCATION2=\"global\"\n",
    "ignore_tool_usage=True\n",
    "\n",
    "\n",
    "print(\"\\n--- Running Gemini 3 Preview ---\")\n",
    "time2 = run_graph_transformer(MODEL2, credentials, PROJECT_ID, LOCATION2, chunk_docs, allowed_nodes, allowed_relationships,ignore_tool_usage)\n",
    "\n",
    "print(f\"\\nSummary:\\nGemini 3 Preview: {time2:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
