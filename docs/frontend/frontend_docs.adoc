= LLM Knowledge Graph Builder Frontend

= Objective
This document provides a comprehensive guide for developers on how we build a React application integrated with Neo4j Aura for graph database functionalities. The application allows users to connect to a Neo4j Aura instance and we show you how to automatically create a graph from the unstructured text. We allow users to upload documents locally and from cloud buckets, YouTube videos, and Wikipedia pages, configure a graph schema, extract the lexical, entity and knowledge graph, visualize the extracted graph, ask questions and see the details that were used to generate the answers.

= Architecture Structure 
* For Knowledge Graph builder App:
      ** React JS – Application logic.
      ** Axios – for network calls and handling responses
      ** Styled Components – To handle CSS in JS – Where we write all CSS ourselves, Or Tailwind CSS – 3rd party CSS classes to speed up development.
      ** LongPooling: Long polling can be conceptualized as the simplest way to maintain a steady connection between a client and a server.It holds the request for a period if it has no response to send it back.It regularly updates clients with new information like updating a status, processed chunks every minute with new data.
      ** SSEs are the best options when the server generates the data in a loop and sends multiple events to the clients and if we need real-time traffic from the server to the client.

image::project architecture.png[Archirecture diagram, 600, align='left']

= Folders
    .
    ├── Components 
    |    ├─ ChatBot
    |    |   ├─ ChatBotInfoModal
    |    |   ├─ ChatModeToggle
    |    |   ├─ ExpandedChatButtonContainer
    |    ├─ Data Sources
    |    |   ├─ AWS
    |    |   ├─ GCS
    |    |   ├─ Local
    |    |   ├─ WebSources
    |    |   |   ├─Web
    |    |   |   ├─Wikipedia
    |    |   |   ├─Youtube
    |    ├─ Graph
    |    |   ├─ GraphViewButton
    |    |   ├─ GraphViewModal
    |    |   ├─ LegendsChip
    |    ├─ Layout
    |    |   ├─ Content
    |    |   ├─ DrawerChatbot
    |    |   ├─ DrawerDropzone
    |    |   ├─ Header
    |    |   ├─ PageLayout
    |    |   ├─ SideNav
    |    ├─ Popups
    |    |   ├─ ConnectionModal
    |    |   ├─ DeletePopup
    |    |   ├─ GraphEnhancementDialog
    |    |   ├─ LargeFilePopup
    |    |   ├─ Settings
    |    ├─ UI
    |    |   ├─ Alert
    |    |   ├─ ButtonWithTooltip
    |    |   ├─ CustomButton
    |    |   ├─ CustomModal
    |    |   ├─ CustomProgressBar
    |    |   ├─ CustomSourceInput
    |    |   ├─ Dropdown
    |    |   ├─ ErrorBoundary
    |    |   ├─ FileTable
    |    |   ├─ GenericSourceButton
    |    |   ├─ GenericSourceModal
    |    |   ├─ HoverableLink
    |    |   ├─ IconButtonTooltip
    |    |   ├─ Legend
    |    |   ├─ Menu
    |    |   ├─ QuickStarter
    ├── HOC
    |    ├─ SettingModalHOC
    ├── Assets
    |    ├─ images
    |    |   ├─ Application Images
    |    ├─ chatbotMessages.json
    |    ├─ schema.json
    ├── Context
    |    ├─ Alert
    |    ├─ ThemeWrapper
    |    ├─ UserCredentials
    |    ├─ UserMessages
    |    ├─ UserFiles
    ├── Hooks
    |    ├─ useSourceInput
    |    ├─ useSpeech
    |    ├─ useSSE
    ├── Services
    ├── Styling
    |    ├─ info
    ├── Utils
    |    ├─ constants
    |    ├─ FileAPI
    |    ├─ Loader
    |    ├─ Types
    |    ├─ utils
    └── README.md

= Application

== 1.	Setup and Installation: 
Added Node.js with version v21.1.0 and npm on the development machine. 
Install necessary dependencies by running yarn install, such as axios for making HTTP requests and others to interact with the graph.

== 2.	Connect to the Neo4j Aura instance: 
Created a connection modal by adding details including protocol, URI, database name, username, and password. Added a submit button that triggers an API: ***/connect*** and accepts params like uri, password, username and database to establish a connection to the Neo4j Aura instance. Handled the authentication and error scenarios appropriately, by displaying relevant messages. To check whether the backend connection is up and working we hit the API: ***/health***

* Before Connection : 
  * After connection:


== 3.	File Source integration: 
Implemented various file source integrations including drag-and-drop, web sources search that includes YouTube video, Wikipedia link, Amazon S3 file access, and Google Cloud Storage (GCS) file access. This allows users to upload PDF files from local storage or directly from the integrated sources. 
The Api’s are as follows:

* ***/source_list:*** 
  ** to fetch the list of files in the DB

* ***/upload:***
  ** to upload files from Local

* ***/url/scan:*** 
  ** to scan the link or sources of YouTube, Wikipedia, and Web Sources
          
* ***/url/scan:*** 
  ** to scan the files of S3 and GCS.
     *** Add the respective Bucket URL, access key and secret key to access ***S3 files***.
              *** Add the respective Project ID, Bucket name, and folder to access ***GCS files***. User gets a redirect to the authentication page to authenticate their google account.

== 4.	File Source Extraction: 
* ***/extract*** 
  ** to fetch the number of nodes and relationships created.
   *** During Extraction the selected files or all files in ‘New’ state go into ‘Processing’ state and then ‘Completed’ state if there are no failures.

== 5.	Graph Generation: 
* Created a component for generating graphs based on the files in the table, to extract nodes and relationships. When the user clicks on the Preview Graph or on the Table View icon the user can see that the graph model holds three options for viewing: Lexical Graph, Entity Graph and Knowledge Graph.  We utilized Neo4j's graph library to visualize the extracted nodes and relationships in the form of a graph query API: ***/graph_query***. There are options for customizing the graph visualization such as layout algorithms [zoom in, zoom out, fit, refresh], node styling, relationship types.

== 6.	Chatbot: 
* Created a Chatbot Component which has state variables to manage user input and chat messages. Once the user asks the question and clicks on the Ask button API: /chatbot is triggered to send user input to the backend and receive the response. The chat also has options for users to see more details about the chat, text to speech and copy the response.
* ***/chunk_entities:*** 
  ** to fetch the number of sources, chunks and entities 
* There are three modes ***Vector***, ***Graph***, ***Graph+Vector*** that can be provided to the chat to retrieve the answers.
      •	In Vector mode, we only get the sources and chunks . 
      •	Graph Mode: Cypher query and Entities [DEV]
      •	Graph+Vector Mode: Sources, Chunks and Entities

== 6.	Graph Enhancement Settings: 
Users can now set their own Schema for nodes and relations or can already be an existing schema.
 
* ***/schema:*** 
  ** to fetch the existing schema that already exists in the db.
* ***/populate_graph_schema:*** 
  ** to fetch the schema from user entered document text
* ***/delete_unconnected_nodes:***
  ** to remove the lonely entities.

== 7. Interface Design: 
Designed a user-friendly interface that guides users through the process of connecting to Neo4j Aura, accessing file sources, uploading PDF files, and generating graphs.

* ***Components:*** @neo4j-ndl/react
* ***Icons:*** @neo4j-ndl/react/icons
* ***Graph Visualization:*** @neo4j-nvl/react.
* ***NVL:*** @neo4j-nvl/core
* ***CSS:*** Inline styling, tailwind CSS

== 8. Deployment: 
Followed best practices for optimizing performance and security of the deployed application.

* ***Local Deployment:***
  ** Running through docker-compose
  ** By default only OpenAI and Diffbot are enabled since Gemini requires extra GCP configurations.
  ** In your root folder, create a .env file with your OPENAI and DIFFBOT keys (if you want to use both),  
  ** By default, the input sources will be: Local files, Youtube, Wikipedia ,AWS S3 and Webpages. As this default config is applied:
  ** By default,all of the chat modes will be available: vector, graph+vector and graph. If none of the mode is mentioned in the chat modes variable all modes will be available:
  ** You can then run Docker Compose to build and start all components:

[source,indent=0]
----
 * LLM_MODELS="diffbot,openai-gpt-3.5,openai-gpt-4o"
 * REACT_APP_SOURCES="local,youtube,wiki,s3,gcs,web"
 * GOOGLE_CLIENT_ID="xxxx"  [For Google GCS integration]
 * CHAT_MODES="vector,graph+vector"
 * CHUNK_SIZE=5242880
 * TIME_PER_BYTE=2
 * TIME_PER_PAGE=50
 * TIME_PER_CHUNK=4
 * LARGE_FILE_SIZE=5242880
 * ENV="PROD"/ ‘DEV’
 * NEO4J_USER_AGENT="LLM-Graph-Builder/v0.2-dev"
 * BACKEND_API_URL=
 * BLOOM_URL=
 * NPM_TOKEN=
 * BACKEND_PROCESSING_URL=
----
* ***Cloud Deployment:***
  ** To deploy the app and packages on Google Cloud Platform, run the following command on google cloud run
    *** gcloud run deploy 
    *** source location current directory > Frontend
    *** region : 32 [us-central 1]
    *** Allow unauthenticated request : Yes


== 9. API Reference
-----
POST /connect
-----

Neo4j database connection on frontend is done with this API.

**API Parameters :**

* `uri`= Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name

=== Upload Files from Local
----
POST /upload
----

The upload endpoint is designed to handle the uploading of large files by breaking them into smaller chunks. This method ensures that large files can be uploaded efficiently without overloading the server.

**API Parameters :**

* `file`=The file to be uploaded, received in chunks,
* `chunkNumber`=The current chunk number being uploaded,
* `totalChunks`=The total number of chunks the file is divided into (each chunk of 1Mb size),
* `originalname`=The original name of the file,
* `model`=The model associated with the file,
* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name


=== User Defined Schema
----
POST /schema
----

User can set schema for graph generation (i.e. Nodes and relationship labels) in settings panel or get existing db schema through this API. 

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name

=== Graph schema from Input Text
----
POST /populate_graph_schema
----

The API is used to populate a graph schema based on the provided input text, model, and schema description flag.

**API Parameters :**

* `input_text`=The input text used to populate the graph schema.
* `model`=The model to be used for populating the graph schema.
* `is_schema_description_checked`=A flag indicating whether the schema description should be considered.

=== Unstructured Sources
----
POST /url/scan 
----

Create Document node for other sources - s3 bucket, gcs bucket, wikipedia, youtube url and web pages.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name
* `model`= LLM model,
* `source_url`= <s3 bucket url or youtube url> ,
* `aws_access_key_id`= AWS access key,
* `aws_secret_access_key`= AWS secret key,
* `wiki_query`= Wikipedia query sources,
* `gcs_project_id`= GCS project id,
* `gcs_bucket_name`= GCS bucket name,
* `gcs_bucket_folder`= GCS bucket folder,
* `source_type`= s3 bucket/ gcs bucket/ youtube/Wikipedia as source type
* `gcs_project_id`=Form(None),
* `access_token`=Form(None)


=== Extration of Nodes and Relations from Data
----
POST /extract
----

This API is responsible for -

** Reading the content of source provided in the form of langchain Document object from respective langchain loaders 

** Dividing the document into multiple chunks, and make below relations - 
*** PART_OF - relation from Document node to all chunk nodes 
*** FIRST_CHUNK - relation from document node to first chunk node
*** NEXT_CHUNK - relation from a chunk pointing to next chunk of the document.
*** HAS_ENTITY - relation between chunk node and entities extracted from LLM.

** Extracting nodes and relations in the form of GraphDocument from respective LLM.

** Update embedding of chunks and create vector index.

** Update K-Nearest Neighbors graph for similar chunks.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name
* `model`= LLM model,
* `file_name` = File uploaded from device
* `source_url`= <s3 bucket url or youtube url> ,
* `aws_access_key_id`= AWS access key,
* `aws_secret_access_key`= AWS secret key,
* `wiki_query`= Wikipedia query sources,
* `gcs_project_id`=GCS project id,
* `gcs_bucket_name`= GCS bucket name,
* `gcs_bucket_folder`= GCS bucket folder,
* `gcs_blob_filename` = GCS file name,
* `source_type`= local file/ s3 bucket/ gcs bucket/ youtube/ Wikipedia as source,
allowedNodes=Node labels passed from settings panel,
* `allowedRelationship`=Relationship labels passed from settings panel,
* `language`=Language in which wikipedia content will be extracted
     
=== Get list of sources
----
GET /sources_list
----

List all sources (Document nodes) present in Neo4j graph database.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name


=== Post processing after graph generation
----
POST /post_processing :
----

This API is called at the end of processing of whole document to get create k-nearest neighbor relations between similar chunks of document based on KNN_MIN_SCORE which is 0.8 by default and to drop and create a full text index on db labels.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name
* `tasks`= List of tasks to perform

=== Chat with Data
----
POST /chat_bot
----

The API responsible for a chatbot system designed to leverage multiple AI models and a Neo4j graph database, providing answers to user queries. It interacts with AI models from OpenAI and Google's Vertex AI and utilizes embedding models to enhance the retrieval of relevant information.

**Components :** 
 
** Embedding Models - Includes OpenAI Embeddings, VertexAI Embeddings, and SentenceTransformer Embeddings to support vector-based query operations.
** AI Models - OpenAI GPT 3.5, GPT 4o, Gemini Pro, Gemini 1.5 Pro and Groq llama3 can be configured for the chatbot backend to generate responses and process natural language.
** Graph Database (Neo4jGraph) - Manages interactions with the Neo4j database, retrieving, and storing conversation histories.
** Response Generation - Utilizes Vector Embeddings from the Neo4j database, chat history, and the knowledge base of the LLM used.

**API Parameters :**

* `uri`= Neo4j uri
* `userName`= Neo4j database username
* `password`= Neo4j database password
* `model`= LLM model
* `question`= User query for the chatbot
* `session_id`= Session ID used to maintain the history of chats during the user's connection

=== Get entities from chunks
----
POST/chunk_entities
----

This API is used to  get the entities and relations associated with a particular chunk and chunk metadata.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name
* `chunk_ids` = Chunk ids of document


=== Clear chat history
----
POST /clear_chat_bot
----

This API is used to clear the chat history which is saved in Neo4j DB.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name,
* `session_id` = User session id for QA chat

=== View graph for a file
----
POST /graph_query
----

This API is used to view graph for a particular file.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `query_type`= Neo4j database name
* `document_names` = File name for which user wants to view graph

=== SSE event to update processing status
----
GET /update_extract_status 
----

The API provides a continuous update on the extraction status of a specified file. It uses Server-Sent Events (SSE) to stream updates to the client.

**API Parameters :**

* `file_name`=The name of the file whose extraction status is being tracked,
* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name

----
GET /document_status
----

The API gives the extraction status of a specified file. It uses Server-Sent Events (SSE) to stream updates to the client.

**API Parameters :**

* `file_name`=The name of the file whose extraction status is being tracked,
* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name

=== Delete selected documents
----
POST /delete_document_and_entities
----

Deleteion of nodes and relations for multiple files is done through this API. User can choose multiple documents to be deleted, also user have option to delete only 'Document' and 'Chunk' nodes and keep the entities extracted from that document. 

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name,
* `filenames`= List of files to be deleted,
* `source_types`= Document sources(Wikipedia, youtube, etc.),
* `deleteEntities`= Boolean value to check entities deletion is requested or not

=== Cancel processing job
----
POST/cancelled_job
----

This API is responsible for cancelling an in process job.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name,
* `filenames`= Name of the file whose processing need to be stopped, 
* `source_types`= Source of the file

=== Deletion of orpahn nodes
----
POST /delete_unconnected_nodes
----

The API is used to delete unconnected entities from database.

**API Parameters :**

* `uri`=Neo4j uri, 
* `userName`= Neo4j db username, 
* `password`= Neo4j db password, 
* `database`= Neo4j database name,
* `unconnected_entities_list`=selected entities list to delete of unconnected entities.


== 10. Conclusion: 
In conclusion, this technical document outlines the process of building a React application with Neo4j Aura integration for graph database functionalities.


== 11. Referral Links: 
Dev env : https://dev-frontend-dcavk67s4a-uc.a.run.app/
Staging env: https://staging-frontend-dcavk67s4a-uc.a.run.app/
Prod env:  https://prod-frontend-dcavk67s4a-uc.a.run.app/



